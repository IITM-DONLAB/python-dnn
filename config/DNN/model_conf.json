{	
    "comment" : "nnetType :: (Mandatory) specify Type of Network (CNN,RBM) ",
    "nnetType" : "DNN",

    "comment" : "train_data :: (Mandatory) specify the working directory containing data configuration and output ",
    "wdir" : "wdir",

    "comment" : "valid_data (Mandatory) specify the path of the validation data relative current directory",
    "data_spec" : "data_spec.json",
    
    "comment" : "rbm_nnet_spec:: (Mandatory) specify the path of RBM network configuration specification relative to current directory",
    "nnet_spec" : "dnn_spec.json",

    "comment" : "output_file :: (Mandatory) specify the path of RBM network output file relative to working directory",
    "output_file" : "dnn_out.model",
    
    "comment" : "batch_size :: specify the mini batch size while training, default 128",
    "batch_size" : 128,

    "comment": "",
    "n_ins":2352,

    "comment":"",
    "n_outs":200,

    "comment" : "input_file :: (Mandatory) specify the path of PreTrained network input file relative to working directory",
    "input_file" : "rbm_in.model",

    "comment" : "finetune_method::  Two methods are supported  C: Constant learning rate and E : Exponential decay",
    "finetune_method":"C",

    "comment" : "finetune_rate :: learning rate configuration",
    "finetune_rate" : {
	"learning_rate" : 0.08,
	"epoch_num" : 10,

	"start_rate" : 0.08,
	"scale_by" : 0.5,
	"min_derror_decay_start" : 0.05,
	"min_derror_stop" : 0.05,
	"min_epoch_decay_start" : 15,
	"init_error" :100
    },

    "comment" : "finetune_momentum ::  Specify the momentum factor while finetuning",
    "finetune_momentum": 0.5,

    "processes":{
	"pretraining":false,
	"finetuning":true,
	"testing":false,
	"export_data":false
    }

}
